{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Model Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will develop the API that will call our model. This module initializes the model, transforms the input so that it is in the appropriate format and defines the scoring method that will produce the predictions. The API will expect the input to be in JSON format. Once  a request is received, the API will convert the json encoded request body into the image format. There are two main functions in the API. The first function loads the model and returns a scoring function. The second function process the images and uses the first function to score them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from testing_utilities import img_url_to_json\n",
    "from pprint import pprint\n",
    "from azureml.core.webservice import Webservice, AksWebservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the writefile magic to write the contents of the below cell to score.py which includes the driver methods. It is important that the file have two methods ```init``` and ```run```. These two functions define the contract with the Flask web application. Have a look here at another example\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/service/tutorial-deploy-models-with-aml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py \n",
    "import base64\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import timeit as t\n",
    "from io import BytesIO\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "import sys\n",
    "from azureml.core.model import Model\n",
    "from glob import glob\n",
    "import warnings\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, stream=sys.stdout) # TODO: remove\n",
    "\n",
    "\n",
    "_LABEL_FILE = os.getenv(\"LABEL_FILE\", \"synset.txt\")\n",
    "_MODEL_NAME = os.getenv(\"MODEL_NAME\", \"pytorch_resnet152\")\n",
    "_NUMBER_RESULTS = 3\n",
    "\n",
    "\n",
    "class ModelFileNotFoundError(Exception):\n",
    "    pass\n",
    "\n",
    "def _create_label_lookup(label_path):\n",
    "    with open(label_path, \"r\") as f:\n",
    "        label_list = [l.rstrip() for l in f]\n",
    "\n",
    "    def _label_lookup(*label_locks):\n",
    "        return [label_list[l] for l in label_locks]\n",
    "\n",
    "    return _label_lookup\n",
    "\n",
    "\n",
    "def _load_model():\n",
    "    logger = logging.getLogger(\"model_driver\")\n",
    "    # Load the model\n",
    "    model_path = Model.get_model_path(_MODEL_NAME)\n",
    "    \n",
    "    file_list = glob(os.path.join(_MODEL_NAME,'*.pth'))\n",
    "    if len(file_list)==0:\n",
    "        raise ModelFileNotFoundError(f'Appropriate model not found in {_MODEL_NAME}')\n",
    "    elif len(file_list)>1:\n",
    "        warnings.warn(\"More than one model found. Selecting first model\")\n",
    "\n",
    "    filename = file_list[0]\n",
    "    logger.debug(f'Loading {filename}')\n",
    "    \n",
    "    # ResNet 152\n",
    "    model = models.ResNet(models.resnet.Bottleneck, [3, 8, 36, 3])\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    \n",
    "    model = model.cuda()\n",
    "    softmax = nn.Softmax(dim=1).cuda()\n",
    "    model = model.eval()\n",
    "\n",
    "    preprocess_input = transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.Resize((224, 224), interpolation=PIL.Image.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def predict_for(image):\n",
    "        image = preprocess_input(image)\n",
    "        with torch.no_grad():\n",
    "            image = image.unsqueeze(0)\n",
    "            image_gpu = image.type(torch.float).cuda()\n",
    "            outputs = model(image_gpu)\n",
    "            pred_proba = softmax(outputs)\n",
    "        return pred_proba.cpu().numpy().squeeze()\n",
    "\n",
    "    return predict_for\n",
    "\n",
    "\n",
    "def _base64img_to_pil_image(base64_img_string):\n",
    "    if base64_img_string.startswith(\"b'\"):\n",
    "        base64_img_string = base64_img_string[2:-1]\n",
    "    base64Img = base64_img_string.encode(\"utf-8\")\n",
    "\n",
    "    # Preprocess the input data\n",
    "    decoded_img = base64.b64decode(base64Img)\n",
    "    img_buffer = BytesIO(decoded_img)\n",
    "\n",
    "    # Load image with PIL (RGB)\n",
    "    pil_img = Image.open(img_buffer).convert(\"RGB\")\n",
    "    return pil_img\n",
    "\n",
    "\n",
    "def create_scoring_func(label_path=_LABEL_FILE):\n",
    "    logger = logging.getLogger(\"model_driver\")\n",
    "\n",
    "    start = t.default_timer()\n",
    "    labels_for = _create_label_lookup(label_path)\n",
    "    predict_for = _load_model()\n",
    "    end = t.default_timer()\n",
    "\n",
    "    loadTimeMsg = \"Model loading time: {0} ms\".format(round((end - start) * 1000, 2))\n",
    "    logger.info(loadTimeMsg)\n",
    "\n",
    "    def _call_model(image, number_results=_NUMBER_RESULTS):\n",
    "        pred_proba = predict_for(image).squeeze()\n",
    "        selected_results = np.flip(np.argsort(pred_proba), 0)[:number_results]\n",
    "        labels = labels_for(*selected_results)\n",
    "        return list(zip(labels, pred_proba[selected_results].astype(np.float64)))\n",
    "\n",
    "    return _call_model\n",
    "\n",
    "\n",
    "def get_model_api():\n",
    "    logger = logging.getLogger(\"model_driver\")\n",
    "    scoring_func = create_scoring_func()\n",
    "\n",
    "    def _process_and_score(images_dict, number_results=_NUMBER_RESULTS):\n",
    "        start = t.default_timer()\n",
    "\n",
    "        results = {}\n",
    "        for key, base64_img_string in images_dict.items():\n",
    "            rgb_image = _base64img_to_pil_image(base64_img_string)\n",
    "            results[key] = scoring_func(rgb_image, number_results=number_results)\n",
    "\n",
    "        end = t.default_timer()\n",
    "\n",
    "        logger.debug(\"Predictions: {0}\".format(results))\n",
    "        logger.info(\"Predictions took {0} ms\".format(round((end - start) * 1000, 2)))\n",
    "        return (results, \"Computed in {0} ms\".format(round((end - start) * 1000, 2)))\n",
    "\n",
    "    return _process_and_score\n",
    "\n",
    "def version():\n",
    "    return torch.__version__\n",
    "\n",
    "def init():\n",
    "    \"\"\" Initialise the model and scoring function\n",
    "    \"\"\"\n",
    "    global process_and_score\n",
    "    process_and_score = get_model_api()\n",
    "\n",
    "def run(raw_data):\n",
    "    \"\"\" Make a prediction based on the data passed in using the preloaded model\n",
    "    \"\"\"\n",
    "    return process_and_score(json.loads(raw_data)['input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the file driver.py which will bring everything into the context of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same Lynx image we used ealier to check that our driver works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGEURL = \"https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Lynx_lynx_poing.jpg/220px-Lynx_lynx_poing.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:azureml.core.model:RunEnvironmentException: Failed to load a submitted run, if outside of an execution context, use project.start_run to initialize an azureml.core.Run.\n",
      "DEBUG:azureml.core.model:Checking root for pytorch_resnet152 because candidate dir azureml-models had 0 nodes: \n",
      "DEBUG:model_driver:Loading pytorch_resnet152/resnet152-b121ed2d.pth\n",
      "INFO:model_driver:Model loading time: 1950.18 ms\n"
     ]
    }
   ],
   "source": [
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:azureml.core.model:RunEnvironmentException: Failed to load a submitted run, if outside of an execution context, use project.start_run to initialize an azureml.core.Run.\n",
      "DEBUG:azureml.core.model:Checking root for pytorch_resnet152 because candidate dir azureml-models had 0 nodes: \n",
      "DEBUG:model_driver:Loading pytorch_resnet152/resnet152-b121ed2d.pth\n",
      "INFO:model_driver:Model loading time: 1833.64 ms\n"
     ]
    }
   ],
   "source": [
    "predict_for = get_model_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonimg = img_url_to_json(IMAGEURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:PIL.PngImagePlugin:STREAM b'IHDR' 16 13\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'iCCP' 41 292\n",
      "DEBUG:PIL.PngImagePlugin:iCCP profile name b'ICC Profile'\n",
      "DEBUG:PIL.PngImagePlugin:Compression method 0\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IDAT' 345 65536\n",
      "DEBUG:model_driver:Predictions: {'image': [('n02127052 lynx, catamount', 0.9965722560882568), ('n02128757 snow leopard, ounce, Panthera uncia', 0.0013256857637315989), ('n02128385 leopard, Panthera pardus', 0.0009192763245664537)]}\n",
      "INFO:model_driver:Predictions took 36.73 ms\n"
     ]
    }
   ],
   "source": [
    "resp = run(jsonimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': [('n02127052 lynx, catamount', 0.9965722560882568),\n",
      "           ('n02128757 snow leopard, ounce, Panthera uncia',\n",
      "            0.0013256857637315989),\n",
      "           ('n02128385 leopard, Panthera pardus', 0.0009192763245664537)]}\n"
     ]
    }
   ],
   "source": [
    "pprint(resp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can move on to [building our docker image](02_BuildImage.ipynb)."
   ]
  }
 ],
 "metadata": {
  "jupytext_format_version": "1.3",
  "jupytext_formats": "py:light",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
