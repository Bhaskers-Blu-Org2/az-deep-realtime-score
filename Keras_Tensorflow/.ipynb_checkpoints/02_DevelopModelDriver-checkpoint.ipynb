{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Model Driver\n",
    "\n",
    "In this notebook, we will develop the API that will call our model. This module initializes the model, transforms the input so that it is in the appropriate format and defines the scoring method that will produce the predictions. The API will expect the input to be in JSON format. Once a request is received, the API will convert the json encoded request body into the image format. There are two main functions in the API. The first function loads the model and returns a scoring function. The second function process the images and uses the first function to score them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.image import Image\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.74\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write and save driver script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing driver.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile driver.py\n",
    "def init():\n",
    "    import tensorflow as tf\n",
    "    from resnet152 import ResNet152\n",
    "    from keras.preprocessing import image\n",
    "    from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "    import numpy as np\n",
    "    import timeit as t\n",
    "    import base64\n",
    "    import json\n",
    "    from PIL import Image, ImageOps\n",
    "    from io import BytesIO\n",
    "    import logging\n",
    "\n",
    "    global model\n",
    "    model = ResNet152(weights='imagenet')\n",
    "    print('Model loaded')\n",
    "    \n",
    "def run(inputString):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    from resnet152 import ResNet152\n",
    "    from keras.preprocessing import image\n",
    "    from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "    import numpy as np\n",
    "    import timeit as t\n",
    "    import base64\n",
    "    import json\n",
    "    from PIL import Image, ImageOps\n",
    "    from io import BytesIO\n",
    "    import logging   \n",
    "    \n",
    "    model = ResNet152(weights='imagenet')\n",
    "    print('Model loaded')\n",
    "  \n",
    "    responses = []\n",
    "    base64Dict = json.loads(inputString)\n",
    "\n",
    "    for k, v in base64Dict.items():\n",
    "        img_file_name, base64Img = k, v\n",
    "    decoded_img = base64.b64decode(base64Img)\n",
    "    img_buffer = BytesIO(decoded_img)\n",
    "    imageData = Image.open(img_buffer).convert(\"RGB\")\n",
    "    \n",
    "    # Evaluate the model using the input data\n",
    "    img = ImageOps.fit(imageData, (224,224), Image.ANTIALIAS)\n",
    "    img = np.array(img) # shape: (224, 224, 3)\n",
    "    \n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    \n",
    "    preds = model.predict(img)\n",
    "    print('Predicted:', decode_predictions(preds, top=3))\n",
    "    resp = {img_file_name: str(decode_predictions(preds, top=3))}\n",
    "\n",
    "    responses.append(resp)\n",
    "    return json.dumps(responses)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run driver.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the driverÂ¶ \n",
    "We test the driver by passing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Predicted: [[('n02127052', 'lynx', 0.9816487), ('n02128385', 'leopard', 0.007744099), ('n02123159', 'tiger_cat', 0.0036861112)]]\n",
      "[{\"220px-Lynx_lynx_poing.jpg\": \"[[('n02127052', 'lynx', 0.9816487), ('n02128385', 'leopard', 0.007744099), ('n02123159', 'tiger_cat', 0.0036861112)]]\"}]\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image, ImageOps\n",
    "import base64\n",
    "import json\n",
    "\n",
    "img_path = '220px-Lynx_lynx_poing.jpg'\n",
    "encoded = None\n",
    "with open(img_path, 'rb') as file:\n",
    "  encoded = base64.b64encode(file.read())\n",
    "img_dict = {img_path: encoded.decode('utf-8')}\n",
    "body = json.dumps(img_dict)\n",
    "\n",
    "resp = run(body)\n",
    "print(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
