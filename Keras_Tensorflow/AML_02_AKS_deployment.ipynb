{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer to \n",
    "https://github.com/Azure/ViennaDocs/blob/master/PrivatePreview/notebooks/01.train-within-notebook.ipynb\n",
    "https://github.com/Azure/ViennaDocs/blob/master/PrivatePreview/notebooks/11.production-deploy-to-aks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.image import Image\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.4\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/jayaubuntudsvm/Desktop/AKSDeploymentTutorial/Keras_Tensorflow/aml_config/config.json\n",
      "jayavienna\n",
      "jayavienna\n",
      "eastus2\n",
      "edf507a2-6235-46c5-b560-fd463ba2e771\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Creating the model pickle file\n",
    "import tensorflow as tf\n",
    "from resnet152 import ResNet152\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "model = ResNet152(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fd9771b9668>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_resnet.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_resnet_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import model_from_json\n",
    "#model = model_from_json(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_resnet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7fd9771b9668>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model resnet_model\n",
      "resnet_model resnet 152 model 10\n"
     ]
    }
   ],
   "source": [
    "#Register the model\n",
    "from azureml.core.model import Model\n",
    "model = Model.register(model_path = \"model_resnet_weights.h5\", # this points to a local file\n",
    "                       model_name = \"resnet_model\", # this is the name the model is registered as\n",
    "                       tags = [\"dl\", \"resnet\"],\n",
    "                       description = \"resnet 152 model\",\n",
    "                       workspace = ws)\n",
    "\n",
    "print(model.name, model.description, model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define init() function\n",
    "def init():\n",
    "    import tensorflow as tf\n",
    "    from resnet152 import ResNet152\n",
    "    from keras.preprocessing import image\n",
    "    from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "    import numpy as np\n",
    "    import timeit as t\n",
    "    import base64\n",
    "    import json\n",
    "    from PIL import Image, ImageOps\n",
    "    from io import BytesIO\n",
    "    import logging\n",
    "\n",
    "    global model\n",
    "    model = ResNet152(weights='imagenet')\n",
    "    print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define run() function \n",
    "def run(img_path):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    from resnet152 import ResNet152\n",
    "    from keras.preprocessing import image\n",
    "    from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "    import numpy as np\n",
    "    import timeit as t\n",
    "    import base64\n",
    "    import json\n",
    "    from PIL import Image, ImageOps\n",
    "    from io import BytesIO\n",
    "    import logging   \n",
    "    \n",
    "    model = ResNet152(weights='imagenet')\n",
    "    print('Model loaded')\n",
    "  \n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    \n",
    "    preds = model.predict(img)\n",
    "    print('Predicted:', decode_predictions(preds, top=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'220px-Lynx_lynx_poing (4).jpg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "wget.download('https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Lynx_lynx_poing.jpg/220px-Lynx_lynx_poing.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '220px-Lynx_lynx_poing.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Predicted: [[('n02127052', 'lynx', 0.9959085), ('n02128385', 'leopard', 0.0011504436), ('n02123159', 'tiger_cat', 0.0009417995)]]\n"
     ]
    }
   ],
   "source": [
    "run(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "def init():\n",
    "    import tensorflow as tf\n",
    "    from resnet152 import ResNet152\n",
    "    from keras.preprocessing import image\n",
    "    from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "    import numpy as np\n",
    "    import timeit as t\n",
    "    import base64\n",
    "    import json\n",
    "    from PIL import Image, ImageOps\n",
    "    from io import BytesIO\n",
    "    import logging\n",
    "\n",
    "    global model\n",
    "    model = ResNet152(weights='imagenet')\n",
    "    print('Model loaded')\n",
    "    \n",
    "def run(img_path):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    from resnet152 import ResNet152\n",
    "    from keras.preprocessing import image\n",
    "    from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "    import numpy as np\n",
    "    import timeit as t\n",
    "    import base64\n",
    "    import json\n",
    "    from PIL import Image, ImageOps\n",
    "    from io import BytesIO\n",
    "    import logging   \n",
    "    \n",
    "    model = ResNet152(weights='imagenet')\n",
    "    print('Model loaded')\n",
    "  \n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    \n",
    "    preds = model.predict(img)\n",
    "    print('Predicted:', decode_predictions(preds, top=3))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run score.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing resnet152_n.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile resnet152_n.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"ResNet152 model for Keras.\n",
    "\n",
    "# Reference:\n",
    "\n",
    "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "Adaptation of code from flyyufelix, mvoelk, BigMoyan, fchollet at https://github.com/adamcasson/resnet152\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import add\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils import layer_utils\n",
    "from keras import initializers\n",
    "from keras.engine import Layer, InputSpec\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(3000)\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/adamcasson/resnet152/releases/download/v0.1/resnet152_weights_tf.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/adamcasson/resnet152/releases/download/v0.1/resnet152_weights_tf_notop.h5'\n",
    "\n",
    "class Scale(Layer):\n",
    "    \"\"\"Custom Layer for ResNet used for BatchNormalization.\n",
    "    \n",
    "    Learns a set of weights and biases used for scaling the input data.\n",
    "    the output consists simply in an element-wise multiplication of the input\n",
    "    and a sum of a set of constants:\n",
    "\n",
    "        out = in * gamma + beta,\n",
    "\n",
    "    where 'gamma' and 'beta' are the weights and biases larned.\n",
    "\n",
    "    Keyword arguments:\n",
    "    axis -- integer, axis along which to normalize in mode 0. For instance,\n",
    "        if your input tensor has shape (samples, channels, rows, cols),\n",
    "        set axis to 1 to normalize per feature map (channels axis).\n",
    "    momentum -- momentum in the computation of the exponential average \n",
    "        of the mean and standard deviation of the data, for \n",
    "        feature-wise normalization.\n",
    "    weights -- Initialization weights.\n",
    "        List of 2 Numpy arrays, with shapes:\n",
    "        `[(input_shape,), (input_shape,)]`\n",
    "    beta_init -- name of initialization function for shift parameter \n",
    "        (see [initializers](../initializers.md)), or alternatively,\n",
    "        Theano/TensorFlow function to use for weights initialization.\n",
    "        This parameter is only relevant if you don't pass a `weights` argument.\n",
    "    gamma_init -- name of initialization function for scale parameter (see\n",
    "        [initializers](../initializers.md)), or alternatively,\n",
    "        Theano/TensorFlow function to use for weights initialization.\n",
    "        This parameter is only relevant if you don't pass a `weights` argument.\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, weights=None, axis=-1, momentum = 0.9, beta_init='zero', gamma_init='one', **kwargs):\n",
    "        self.momentum = momentum\n",
    "        self.axis = axis\n",
    "        self.beta_init = initializers.get(beta_init)\n",
    "        self.gamma_init = initializers.get(gamma_init)\n",
    "        self.initial_weights = weights\n",
    "        super(Scale, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        shape = (int(input_shape[self.axis]),)\n",
    "\n",
    "        self.gamma = K.variable(self.gamma_init(shape), name='%s_gamma'%self.name)\n",
    "        self.beta = K.variable(self.beta_init(shape), name='%s_beta'%self.name)\n",
    "        self.trainable_weights = [self.gamma, self.beta]\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        input_shape = self.input_spec[0].shape\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "\n",
    "        out = K.reshape(self.gamma, broadcast_shape) * x + K.reshape(self.beta, broadcast_shape)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"momentum\": self.momentum, \"axis\": self.axis}\n",
    "        base_config = super(Scale, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity_block is the block that has no conv layer at shortcut\n",
    "    \n",
    "    Keyword arguments\n",
    "    input_tensor -- input tensor\n",
    "    kernel_size -- defualt 3, the kernel size of middle conv layer at main path\n",
    "    filters -- list of integers, the nb_filters of 3 conv layer at main path\n",
    "    stage -- integer, current stage label, used for generating layer names\n",
    "    block -- 'a','b'..., current block label, used for generating layer names\n",
    "    \n",
    "    \"\"\"\n",
    "    eps = 1.1e-5\n",
    "    \n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    \n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(nb_filter1, (1, 1), name=conv_name_base + '2a', use_bias=False)(input_tensor)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
    "    x = Conv2D(nb_filter2, (kernel_size, kernel_size), name=conv_name_base + '2b', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
    "\n",
    "    x = Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
    "\n",
    "    x = add([x, input_tensor], name='res' + str(stage) + block)\n",
    "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
    "    \n",
    "    Keyword arguments:\n",
    "    input_tensor -- input tensor\n",
    "    kernel_size -- defualt 3, the kernel size of middle conv layer at main path\n",
    "    filters -- list of integers, the nb_filters of 3 conv layer at main path\n",
    "    stage -- integer, current stage label, used for generating layer names\n",
    "    block -- 'a','b'..., current block label, used for generating layer names\n",
    "        \n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    \n",
    "    \"\"\"\n",
    "    eps = 1.1e-5\n",
    "    \n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    \n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(nb_filter1, (1, 1), strides=strides, name=conv_name_base + '2a', use_bias=False)(input_tensor)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
    "    x = Conv2D(nb_filter2, (kernel_size, kernel_size),\n",
    "                      name=conv_name_base + '2b', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
    "\n",
    "    x = Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(nb_filter3, (1, 1), strides=strides,\n",
    "                             name=conv_name_base + '1', use_bias=False)(input_tensor)\n",
    "    shortcut = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "    shortcut = Scale(axis=bn_axis, name=scale_name_base + '1')(shortcut)\n",
    "\n",
    "    x = add([x, shortcut], name='res' + str(stage) + block)\n",
    "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
    "    return x\n",
    "\n",
    "def ResNet152(include_top=True, weights=None,\n",
    "              input_tensor=None, input_shape=None,\n",
    "              large_input=False, pooling=None,\n",
    "              classes=1000):\n",
    "    \"\"\"Instantiate the ResNet152 architecture.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    include_top -- whether to include the fully-connected layer at the \n",
    "        top of the network. (default True)\n",
    "    weights -- one of `None` (random initialization) or \"imagenet\" \n",
    "        (pre-training on ImageNet). (default None)\n",
    "    input_tensor -- optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "        to use as image input for the model.(default None)\n",
    "    input_shape -- optional shape tuple, only to be specified if \n",
    "        `include_top` is False (otherwise the input shape has to be \n",
    "        `(224, 224, 3)` (with `channels_last` data format) or \n",
    "        `(3, 224, 224)` (with `channels_first` data format). It should \n",
    "        have exactly 3 inputs channels, and width and height should be \n",
    "        no smaller than 197. E.g. `(200, 200, 3)` would be one valid value.\n",
    "        (default None)\n",
    "    large_input -- if True, then the input shape expected will be \n",
    "        `(448, 448, 3)` (with `channels_last` data format) or \n",
    "        `(3, 448, 448)` (with `channels_first` data format). (default False)\n",
    "    pooling -- Optional pooling mode for feature extraction when \n",
    "        `include_top` is `False`.\n",
    "        - `None` means that the output of the model will be the 4D \n",
    "            tensor output of the last convolutional layer.\n",
    "        - `avg` means that global average pooling will be applied to \n",
    "            the output of the last convolutional layer, and thus\n",
    "            the output of the model will be a 2D tensor.\n",
    "        - `max` means that global max pooling will be applied.\n",
    "        (default None)\n",
    "    classes -- optional number of classes to classify image into, only \n",
    "        to be specified if `include_top` is True, and if no `weights` \n",
    "        argument is specified. (default 1000)\n",
    "            \n",
    "    Returns:\n",
    "    A Keras model instance.\n",
    "        \n",
    "    Raises:\n",
    "    ValueError: in case of invalid argument for `weights`,\n",
    "        or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    \n",
    "    eps = 1.1e-5\n",
    "    \n",
    "    if large_input:\n",
    "        img_size = 448\n",
    "    else:\n",
    "        img_size = 224\n",
    "    \n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=img_size,\n",
    "                                      min_size=197,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    "    \n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    # handle dimension ordering for different backends\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "            \n",
    "    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Scale(axis=bn_axis, name='scale_conv1')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    for i in range(1,8):\n",
    "        x = identity_block(x, 3, [128, 128, 512], stage=3, block='b'+str(i))\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    for i in range(1,36):\n",
    "        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b'+str(i))\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    if large_input:\n",
    "        x = AveragePooling2D((14, 14), name='avg_pool')(x)\n",
    "    else:\n",
    "        x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "    \n",
    "    # include classification layer by default, not included for feature extraction \n",
    "    if include_top:\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, activation='softmax', name='fc1000')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "    \n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnet152')\n",
    "    \n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('resnet152_weights_tf.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='cdb18a2158b88e392c0905d47dcef965')\n",
    "        else:\n",
    "            weights_path = get_file('resnet152_weights_tf_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models',\n",
    "                                    md5_hash='4a90dcdafacbd17d772af1fb44fc2660')\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='avg_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1000')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "                \n",
    "        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n",
    "            warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                          'are using the Theano '\n",
    "                          'image data format convention '\n",
    "                          '(`image_data_format=\"channels_first\"`). '\n",
    "                          'For best performance, set '\n",
    "                          '`image_data_format=\"channels_last\"` in '\n",
    "                          'your Keras config '\n",
    "                          'at ~/.keras/keras.json.')\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = ResNet152(include_top=True, weights='imagenet')\n",
    "    \n",
    "    img_path = '220px-Lynx_lynx_poing.jpg'\n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    print('Input image shape:', x.shape)\n",
    "\n",
    "    preds = model.predict(x)\n",
    "    print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: (1, 224, 224, 3)\n",
      "Predicted: [[('n02127052', 'lynx', 0.9959085), ('n02128385', 'leopard', 0.0011504436), ('n02123159', 'tiger_cat', 0.0009417995), ('n02124075', 'Egyptian_cat', 0.00051911507), ('n02128757', 'snow_leopard', 0.0003321905)]]\n"
     ]
    }
   ],
   "source": [
    "%run resnet152_n.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def init():\n",
      "    import tensorflow as tf\n",
      "    from resnet152 import ResNet152\n",
      "    from keras.preprocessing import image\n",
      "    from keras.applications.imagenet_utils import preprocess_input, decode_predi\n",
      "ctions\n",
      "\n",
      "    import numpy as np\n",
      "    import timeit as t\n",
      "    import base64\n",
      "    import json\n",
      "    from PIL import Image, ImageOps\n",
      "    from io import BytesIO\n",
      "    import logging\n",
      "\n",
      "    global model\n",
      "    model = ResNet152(weights='imagenet')\n",
      "    print('Model loaded')\n",
      "    \n",
      "def run(img_path):\n",
      "    \n",
      "    import tensorflow as tf\n",
      "    from resnet152 import ResNet152\n",
      "\u001b[Km--More--(46%)\u001b[m"
     ]
    }
   ],
   "source": [
    "!more score.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-fil\n",
      "e-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - --index-url https://azuremlsdktestpypi.azureedge.net/sdk-release/Preview/E75\n",
      "01C02541B433786111FE8E140CAA1\n",
      "  - --extra-index-url https://pypi.python.org/simple\n",
      "  - azureml-defaults\n",
      "  - papermill==0.14.1\n",
      "  - python-dotenv==0.9.0\n",
      "  - Pillow==5.2.0\n",
      "  - wget==3.2\n",
      "\u001b[Km--More--(86%)\u001b[m"
     ]
    }
   ],
   "source": [
    "!more conda_dependencies.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -*- coding: utf-8 -*-\n",
      "\"\"\"ResNet152 model for Keras.\n",
      "\n",
      "# Reference:\n",
      "\n",
      "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.0338\n",
      "5)\n",
      "\n",
      "Adaptation of code from flyyufelix, mvoelk, BigMoyan, fchollet at https://github\n",
      ".com/adamcasson/resnet152\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "import numpy as np\n",
      "import warnings\n",
      "\n",
      "from keras.layers import Input\n",
      "from keras.layers import Dense\n",
      "from keras.layers import Activation\n",
      "from keras.layers import Flatten\n",
      "from keras.layers import Conv2D\n",
      "from keras.layers import MaxPooling2D\n",
      "from keras.layers import GlobalMaxPooling2D\n",
      "\u001b[Km--More--(3%)\u001b[m"
     ]
    }
   ],
   "source": [
    "!more resnet152.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jayaubuntudsvm/Desktop/AKSDeploymentTutorial/Keras_Tensorflow'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00_DevelopModel.ipynb',\n",
       " 'AML_02_DevelopModelDriver_AKS-old.ipynb',\n",
       " 'AML_01_trainlocal-docker.ipynb',\n",
       " 'model_resnet_weights.h5',\n",
       " 'AML_02_resnet_model_weights.ipynb',\n",
       " '01_DevelopModelDriver.ipynb',\n",
       " '__pycache__',\n",
       " 'resnet152_n.py',\n",
       " '06_SpeedTestWebApp.ipynb',\n",
       " '03_TestLocally.ipynb',\n",
       " 'AML_02_Develop_init_run_functions.ipynb',\n",
       " 'AML_02_AKS_deployment.ipynb',\n",
       " 'aml_config',\n",
       " '05_TestWebApp.ipynb',\n",
       " '04_DeployOnAKS.ipynb',\n",
       " 'score.py',\n",
       " 'AML_01_trainlocal.ipynb',\n",
       " 'model_resnet.json',\n",
       " '02_BuildImage.ipynb',\n",
       " '07_TearDown.ipynb',\n",
       " 'helpers.py',\n",
       " 'testing_utilities.py',\n",
       " '220px-Lynx_lynx_poing.jpg',\n",
       " 'conda_dependencies.yml',\n",
       " 'resnet152.py',\n",
       " 'README.md',\n",
       " 'environment.yml',\n",
       " 'AML_00_configuration.ipynb',\n",
       " 'sample_projects',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running.................................................\n",
      "SucceededImage creation operation finished for image myimage1:4, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"conda_dependencies.yml\",\n",
    "                                                  description = \"Image for AKS Deployment Tutorial\",\n",
    "                                                  tags = [\"AKS\",\"AML\"],\n",
    "                                                  dependencies = [\"resnet152_n.py\"]\n",
    "                                                 )\n",
    "\n",
    "image = ContainerImage.create(name = \"myimage1\",\n",
    "                              # this is the model object\n",
    "                              models = [],                              \n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ContainerImage(workspace=<azureml.core.workspace.Workspace object at 0x7fda68124b70>, name=myimage1, id=myimage1:4, tag=['AKS', 'AML'], version=4),\n",
       " ContainerImage(workspace=<azureml.core.workspace.Workspace object at 0x7fda68124b70>, name=myimage1, id=myimage1:3, tag=['AKS', 'AML'], version=3),\n",
       " ContainerImage(workspace=<azureml.core.workspace.Workspace object at 0x7fda68124b70>, name=myimage1, id=myimage1:2, tag=['AKS', 'AML'], version=2),\n",
       " ContainerImage(workspace=<azureml.core.workspace.Workspace object at 0x7fda68124b70>, name=myimage1, id=myimage1:1, tag=['AKS', 'AML'], version=1),\n",
       " ContainerImage(workspace=<azureml.core.workspace.Workspace object at 0x7fda68124b70>, name=my-aci-svc-1, id=my-aci-svc-1:4, tag=None, version=4),\n",
       " ContainerImage(workspace=<azureml.core.workspace.Workspace object at 0x7fda68124b70>, name=my-aci-svc-1, id=my-aci-svc-1:3, tag=None, version=3),\n",
       " ContainerImage(workspace=<azureml.core.workspace.Workspace object at 0x7fda68124b70>, name=my-aci-svc-1, id=my-aci-svc-1:2, tag=None, version=2),\n",
       " ContainerImage(workspace=<azureml.core.workspace.Workspace object at 0x7fda68124b70>, name=my-aci-svc-1, id=my-aci-svc-1:1, tag=None, version=1)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list images\n",
    "images = ws.images()\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeTargetException",
     "evalue": "Received bad response from Resource Provider:\nResponse Code: 400\nHeaders: {'Cache-Control': 'no-cache', 'Pragma': 'no-cache', 'Content-Type': 'application/json; charset=utf-8', 'Expires': '-1', 'x-ms-failure-cause': 'gateway', 'x-ms-request-id': '042fe68d-c97e-4343-9ed2-78d88d32ecf5', 'x-ms-correlation-request-id': '042fe68d-c97e-4343-9ed2-78d88d32ecf5', 'x-ms-routing-request-id': 'EASTUS:20180918T174521Z:042fe68d-c97e-4343-9ed2-78d88d32ecf5', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains', 'X-Content-Type-Options': 'nosniff', 'Date': 'Tue, 18 Sep 2018 17:45:21 GMT', 'Content-Length': '246'}\nContent: b'{\"error\":{\"code\":\"LinkedInvalidPropertyId\",\"message\":\"Property id \\'\\' at path \\'properties.resourceId\\' is invalid. Expect fully qualified resource Id that start with \\'/subscriptions/{subscriptionId}\\' or \\'/providers/{resourceProviderNamespace}/\\'.\"}}'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/envs/myenv/lib/python3.6/site-packages/azureml/core/compute/compute.py\u001b[0m in \u001b[0;36m_create_compute_target\u001b[0;34m(workspace, name, compute_payload, target_class)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/myenv/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://management.azure.com/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/jayavienna/providers/Microsoft.MachineLearningServices/workspaces/jayavienna/computes/jaya-aks-1?api-version=2018-03-01-preview",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mComputeTargetException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a44b59b43e1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m aks_target = ComputeTarget.create(workspace = ws, \n\u001b[1;32m      8\u001b[0m                                   \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maks_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                   provisioning_configuration = prov_config)\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/myenv/lib/python3.6/site-packages/azureml/core/compute/compute.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(workspace, name, provisioning_configuration)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[1;32m    154\u001b[0m         \u001b[0mcompute_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprovisioning_configuration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovisioning_configuration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/myenv/lib/python3.6/site-packages/azureml/core/compute/aks.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(workspace, name, provisioning_configuration)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \"\"\"\n\u001b[1;32m     82\u001b[0m         \u001b[0mcompute_create_payload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAksCompute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_create_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprovisioning_configuration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mComputeTarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_compute_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_create_payload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAksCompute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/myenv/lib/python3.6/site-packages/azureml/core/compute/compute.py\u001b[0m in \u001b[0;36m_create_compute_target\u001b[0;34m(workspace, name, compute_payload, target_class)\u001b[0m\n\u001b[1;32m    189\u001b[0m                                          \u001b[0;34m'Response Code: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                                          \u001b[0;34m'Headers: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                                          'Content: {}'.format(resp.status_code, resp.headers, resp.content))\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'Azure-AsyncOperation'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             raise ComputeTargetException('Error, missing operation location from resp headers:\\n'\n",
      "\u001b[0;31mComputeTargetException\u001b[0m: Received bad response from Resource Provider:\nResponse Code: 400\nHeaders: {'Cache-Control': 'no-cache', 'Pragma': 'no-cache', 'Content-Type': 'application/json; charset=utf-8', 'Expires': '-1', 'x-ms-failure-cause': 'gateway', 'x-ms-request-id': '042fe68d-c97e-4343-9ed2-78d88d32ecf5', 'x-ms-correlation-request-id': '042fe68d-c97e-4343-9ed2-78d88d32ecf5', 'x-ms-routing-request-id': 'EASTUS:20180918T174521Z:042fe68d-c97e-4343-9ed2-78d88d32ecf5', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains', 'X-Content-Type-Options': 'nosniff', 'Date': 'Tue, 18 Sep 2018 17:45:21 GMT', 'Content-Length': '246'}\nContent: b'{\"error\":{\"code\":\"LinkedInvalidPropertyId\",\"message\":\"Property id \\'\\' at path \\'properties.resourceId\\' is invalid. Expect fully qualified resource Id that start with \\'/subscriptions/{subscriptionId}\\' or \\'/providers/{resourceProviderNamespace}/\\'.\"}}'"
     ]
    }
   ],
   "source": [
    "#Provision AKS cluster\n",
    "# Use the default configuration (can also provide parameters to customize)\n",
    "prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "aks_name = 'jaya-aks-1' \n",
    "# Create the cluster\n",
    "aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                  name = aks_name, \n",
    "                                  provisioning_configuration = prov_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K - Starting ..\r",
      "\r",
      "\u001b[K - Finished ..\r",
      "\r",
      "\u001b[K\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!az aks delete --resource-group jayavienna --name jaya-aks-1 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aks_target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aks_target' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aks_target.wait_for_provisioning(show_output = True)\n",
    "print(aks_target.provisioning_state)\n",
    "print(aks_target.provisioning_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deploy web service to AKS\n",
    "#Set the web service configuration (using default here)\n",
    "aks_config = AksWebservice.deploy_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "aks_service_name ='jaya-aks-service-2'\n",
    "\n",
    "aks_service = Webservice.deploy_from_image(workspace = ws, \n",
    "                                           name = aks_service_name,\n",
    "                                           image = image,\n",
    "                                           deployment_config = aks_config,\n",
    "                                           deployment_target = aks_target)\n",
    "aks_service.wait_for_deployment(show_output = True)\n",
    "print(aks_service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debug\n",
    "\n",
    "# load workspace from default config file\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# list all web services in the workspace\n",
    "for s in ws.webservices():\n",
    "    print(s.name)\n",
    "\n",
    "# instantiate the web service object from workspace and service name\n",
    "svc = Webservice(workspace = ws, name = 'jaya-aks-service-2')\n",
    "\n",
    "# print out the Docker log\n",
    "print(svc.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeTargetException",
     "evalue": "ComputeTargetNotFound: Compute Target with name jaya-aks-1 not found in provided workspace",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeTargetException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-b5b15fe20f0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#clean up resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maks_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAksCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jaya-aks-1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maks_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/myenv/lib/python3.6/site-packages/azureml/core/compute/compute.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, workspace, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 raise ComputeTargetException('ComputeTargetNotFound: Compute Target with name {} not found in '\n\u001b[0;32m---> 39\u001b[0;31m                                              'provided workspace'.format(name))\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mComputeTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mComputeTargetException\u001b[0m: ComputeTargetNotFound: Compute Target with name jaya-aks-1 not found in provided workspace"
     ]
    }
   ],
   "source": [
    "#clean up resources\n",
    "aks_target = AksCompute(name='jaya-aks-1',workspace=ws)\n",
    "aks_target.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in ws.webservices():\n",
    "    print(s.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "for c in ws.compute_targets():\n",
    "    print(c.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
